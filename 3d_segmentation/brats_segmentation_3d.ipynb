{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7wRgg2lbsK_"
      },
      "source": [
        "Copyright (c) MONAI Consortium  \n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
        "you may not use this file except in compliance with the License.  \n",
        "You may obtain a copy of the License at  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
        "Unless required by applicable law or agreed to in writing, software  \n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
        "See the License for the specific language governing permissions and  \n",
        "limitations under the License.\n",
        "\n",
        "# Brain tumor 3D segmentation with MONAI\n",
        "\n",
        "This tutorial shows how to construct a training workflow of multi-labels segmentation task.\n",
        "\n",
        "And it contains below features:\n",
        "1. Transforms for dictionary format data.\n",
        "1. Define a new transform according to MONAI transform API.\n",
        "1. Load Nifti image with metadata, load a list of images and stack them.\n",
        "1. Randomly adjust intensity for data augmentation.\n",
        "1. Cache IO and transforms to accelerate training and validation.\n",
        "1. 3D SegResNet model, Dice loss function, Mean Dice metric for 3D segmentation task.\n",
        "1. Deterministic training for reproducibility.\n",
        "\n",
        "The dataset comes from http://medicaldecathlon.com/.  \n",
        "Target: Gliomas segmentation necrotic/active tumour and oedema  \n",
        "Modality: Multimodal multisite MRI data (FLAIR, T1w, T1gd,T2w)  \n",
        "Size: 750 4D volumes (484 Training + 266 Testing)  \n",
        "Source: BRATS 2016 and 2017 datasets.  \n",
        "Challenge: Complex and heterogeneously-located targets\n",
        "\n",
        "Below figure shows image patches with the tumor sub-regions that are annotated in the different modalities (top left) and the final labels for the whole dataset (right).\n",
        "(Figure taken from the [BraTS IEEE TMI paper](https://ieeexplore.ieee.org/document/6975210/))\n",
        "\n",
        "![image](https://github.com/Project-MONAI/tutorials/blob/main/figures/brats_tasks.png?raw=1)\n",
        "\n",
        "The image patches show from left to right:\n",
        "1. the whole tumor (yellow) visible in T2-FLAIR (Fig.A).\n",
        "1. the tumor core (red) visible in T2 (Fig.B).\n",
        "1. the enhancing tumor structures (light blue) visible in T1Gd, surrounding the cystic/necrotic components of the core (green) (Fig. C).\n",
        "1. The segmentations are combined to generate the final labels of the tumor sub-regions (Fig.D): edema (yellow), non-enhancing solid core (red), necrotic/cystic core (green), enhancing core (blue).\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/main/3d_segmentation/brats_segmentation_3d.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XOxdh6bbsLA"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a new folder in Drive to store outputs\n",
        "save_path = \"/content/drive/MyDrive/brats_outputs/\"\n",
        "os.makedirs(save_path, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "pwJlRdYvai9O",
        "outputId": "c0374b3b-371b-4818-df11-5a6cff2053c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4iv2S3LbsLA",
        "outputId": "a2994d93-8e85-4aa6-d142-e7a289813f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "ModuleNotFoundError: No module named 'monai'\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTraceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "ModuleNotFoundError: No module named 'onnxruntime'\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m118.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "!python -c \"import onnxruntime\" || pip install -q onnxruntime\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEknXtPQbsLA"
      },
      "source": [
        "## Setup imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siCBWrDobsLA",
        "outputId": "4f076764-61e9-423b-d549-a48a47e1d065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MONAI version: 1.5.dev2517\n",
            "Numpy version: 2.0.2\n",
            "Pytorch version: 2.6.0+cu124\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
            "MONAI rev id: f7de3a02b37a65a78b3cd813929aa4c20c7a5819\n",
            "MONAI __file__: /usr/local/lib/python3.11/dist-packages/monai/__init__.py\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "Nibabel version: 5.3.2\n",
            "scikit-image version: 0.25.2\n",
            "scipy version: 1.15.2\n",
            "Pillow version: 11.2.1\n",
            "Tensorboard version: 2.18.0\n",
            "gdown version: 5.2.0\n",
            "TorchVision version: 0.21.0+cu124\n",
            "tqdm version: 4.67.1\n",
            "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "psutil version: 5.9.5\n",
            "pandas version: 2.2.2\n",
            "einops version: 0.8.1\n",
            "transformers version: 4.51.3\n",
            "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from monai.apps import DecathlonDataset\n",
        "from monai.config import print_config\n",
        "from monai.data import DataLoader, decollate_batch\n",
        "from monai.handlers.utils import from_engine\n",
        "from monai.losses import DiceLoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.networks.nets import SegResNet\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    Activationsd,\n",
        "    AsDiscrete,\n",
        "    AsDiscreted,\n",
        "    Compose,\n",
        "    Invertd,\n",
        "    LoadImaged,\n",
        "    MapTransform,\n",
        "    NormalizeIntensityd,\n",
        "    Orientationd,\n",
        "    RandFlipd,\n",
        "    RandScaleIntensityd,\n",
        "    RandShiftIntensityd,\n",
        "    RandSpatialCropd,\n",
        "    Spacingd,\n",
        "    EnsureTyped,\n",
        "    EnsureChannelFirstd,\n",
        ")\n",
        "from monai.utils import set_determinism\n",
        "import onnxruntime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "\n",
        "print_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz0rvOO4bsLB"
      },
      "source": [
        "## Setup data directory\n",
        "\n",
        "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
        "This allows you to save results and reuse downloads.  \n",
        "If not specified a temporary directory will be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "QzAhjsftbsLB",
        "outputId": "5d383df4-323d-48a8-8085-fed32667bc8a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-15-228a65de8b3d>, line 4)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-228a65de8b3d>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    root_dir = tempfile.mkdtemp() if directory is None else\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
        "if directory is not None:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "root_dir = tempfile.mkdtemp() if directory is None else\n",
        "print(root_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir3WQoqgbsLB"
      },
      "source": [
        "## Set deterministic training for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eqUucV8vbsLB"
      },
      "outputs": [],
      "source": [
        "set_determinism(seed=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykWAbEgSbsLB"
      },
      "source": [
        "## Define a new transform to convert brain tumor labels\n",
        "\n",
        "Here we convert the multi-classes labels into multi-labels segmentation task in One-Hot format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zqZjTh1hbsLB"
      },
      "outputs": [],
      "source": [
        "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
        "    \"\"\"\n",
        "    Convert labels to multi channels based on brats classes:\n",
        "    label 1 is the peritumoral edema\n",
        "    label 2 is the GD-enhancing tumor\n",
        "    label 3 is the necrotic and non-enhancing tumor core\n",
        "    The possible classes are TC (Tumor core), WT (Whole tumor)\n",
        "    and ET (Enhancing tumor).\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, data):\n",
        "        d = dict(data)\n",
        "        for key in self.keys:\n",
        "            result = []\n",
        "            # merge label 2 and label 3 to construct TC\n",
        "            result.append(torch.logical_or(d[key] == 2, d[key] == 3))\n",
        "            # merge labels 1, 2 and 3 to construct WT\n",
        "            result.append(torch.logical_or(torch.logical_or(d[key] == 2, d[key] == 3), d[key] == 1))\n",
        "            # label 2 is ET\n",
        "            result.append(d[key] == 2)\n",
        "            d[key] = torch.stack(result, axis=0).float()\n",
        "        return d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rRhFu5kbsLB"
      },
      "source": [
        "## Setup transforms for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Tqp6CQambsLB"
      },
      "outputs": [],
      "source": [
        "train_transform = Compose(\n",
        "    [\n",
        "        # load 4 Nifti images and stack them together\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=\"image\"),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        Spacingd(\n",
        "            keys=[\"image\", \"label\"],\n",
        "            pixdim=(1.0, 1.0, 1.0),\n",
        "            mode=(\"bilinear\", \"nearest\"),\n",
        "        ),\n",
        "        RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=[224, 224, 144], random_size=False),\n",
        "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
        "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
        "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
        "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
        "        RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
        "        RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
        "    ]\n",
        ")\n",
        "val_transform = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=\"image\"),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        Spacingd(\n",
        "            keys=[\"image\", \"label\"],\n",
        "            pixdim=(1.0, 1.0, 1.0),\n",
        "            mode=(\"bilinear\", \"nearest\"),\n",
        "        ),\n",
        "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtVgTvUgbsLB"
      },
      "source": [
        "## Quickly load data with DecathlonDataset\n",
        "\n",
        "Here we use `DecathlonDataset` to automatically download and extract the dataset.\n",
        "It inherits MONAI `CacheDataset`, if you want to use less memory, you can set `cache_num=N` to cache N items for training and use the default args to cache all the items for validation, it depends on your memory size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "Ax-qSPsobsLB",
        "outputId": "385615d1-0136-4b44-b50a-0f6522a485d5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Root directory root_dir must be a directory.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-eecc61094473>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# here we don't cache any data in case out of memory issue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_ds = DecathlonDataset(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Task01_BrainTumour\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/monai/apps/datasets.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, task, section, transform, download, seed, val_frac, cache_num, cache_rate, num_workers, progress, copy_cache, as_contiguous, runtime_cache)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Root directory root_dir must be a directory.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_frac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_frac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Root directory root_dir must be a directory."
          ]
        }
      ],
      "source": [
        "# here we don't cache any data in case out of memory issue\n",
        "train_ds = DecathlonDataset(\n",
        "    root_dir=root_dir,\n",
        "    task=\"Task01_BrainTumour\",\n",
        "    transform=train_transform,\n",
        "    section=\"training\",\n",
        "    download=True,\n",
        "    cache_rate=0.0,\n",
        "    num_workers=4,\n",
        ")\n",
        "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=4)\n",
        "val_ds = DecathlonDataset(\n",
        "    root_dir=root_dir,\n",
        "    task=\"Task01_BrainTumour\",\n",
        "    transform=val_transform,\n",
        "    section=\"validation\",\n",
        "    download=False,\n",
        "    cache_rate=0.0,\n",
        "    num_workers=4,\n",
        ")\n",
        "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XA745tEbsLB"
      },
      "source": [
        "## Check data shape and visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBuDQ1WmbsLB"
      },
      "outputs": [],
      "source": [
        "# pick one image from DecathlonDataset to visualize and check the 4 channels\n",
        "val_data_example = val_ds[2]\n",
        "print(f\"image shape: {val_data_example['image'].shape}\")\n",
        "plt.figure(\"image\", (24, 6))\n",
        "for i in range(4):\n",
        "    plt.subplot(1, 4, i + 1)\n",
        "    plt.title(f\"image channel {i}\")\n",
        "    plt.imshow(val_data_example[\"image\"][i, :, :, 60].detach().cpu(), cmap=\"gray\")\n",
        "plt.show()\n",
        "# also visualize the 3 channels label corresponding to this image\n",
        "print(f\"label shape: {val_data_example['label'].shape}\")\n",
        "plt.figure(\"label\", (18, 6))\n",
        "for i in range(3):\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    plt.title(f\"label channel {i}\")\n",
        "    plt.imshow(val_data_example[\"label\"][i, :, :, 60].detach().cpu())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYCPNeDbbsLB"
      },
      "source": [
        "## Create Model, Loss, Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTnuuIkibsLB"
      },
      "outputs": [],
      "source": [
        "#max_epochs = 300\n",
        "max_epochs = 20\n",
        "val_interval = 1\n",
        "VAL_AMP = True\n",
        "\n",
        "# standard PyTorch program style: create SegResNet, DiceLoss and Adam optimizer\n",
        "device = torch.device(\"cuda:0\")\n",
        "model = SegResNet(\n",
        "    blocks_down=[1, 2, 2, 4],\n",
        "    blocks_up=[1, 1, 1],\n",
        "    init_filters=16,\n",
        "    in_channels=4,\n",
        "    out_channels=3,\n",
        "    dropout_prob=0.2,\n",
        ").to(device)\n",
        "loss_function = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, to_onehot_y=False, sigmoid=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
        "\n",
        "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
        "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
        "\n",
        "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
        "\n",
        "\n",
        "# define inference method\n",
        "def inference(input):\n",
        "    def _compute(input):\n",
        "        return sliding_window_inference(\n",
        "            inputs=input,\n",
        "            roi_size=(240, 240, 160),\n",
        "            sw_batch_size=1,\n",
        "            predictor=model,\n",
        "            overlap=0.5,\n",
        "        )\n",
        "\n",
        "    if VAL_AMP:\n",
        "        with torch.autocast(\"cuda\"):\n",
        "            return _compute(input)\n",
        "    else:\n",
        "        return _compute(input)\n",
        "\n",
        "\n",
        "# use amp to accelerate training\n",
        "scaler = torch.GradScaler(\"cuda\")\n",
        "# enable cuDNN benchmark\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX1HqgsNbsLB"
      },
      "source": [
        "## Execute a typical PyTorch training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "KEypcVpUbsLC"
      },
      "outputs": [],
      "source": [
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "best_metrics_epochs_and_time = [[], [], []]\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "metric_values_tc = []\n",
        "metric_values_wt = []\n",
        "metric_values_et = []\n",
        "\n",
        "total_start = time.time()\n",
        "for epoch in range(max_epochs):\n",
        "    epoch_start = time.time()\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in train_loader:\n",
        "        step_start = time.time()\n",
        "        step += 1\n",
        "        inputs, labels = (\n",
        "            batch_data[\"image\"].to(device),\n",
        "            batch_data[\"label\"].to(device),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        with torch.autocast(\"cuda\"):\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        epoch_loss += loss.item()\n",
        "        print(\n",
        "            f\"{step}/{len(train_ds) // train_loader.batch_size}\"\n",
        "            f\", train_loss: {loss.item():.4f}\"\n",
        "            f\", step time: {(time.time() - step_start):.4f}\"\n",
        "        )\n",
        "    lr_scheduler.step()\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for val_data in val_loader:\n",
        "                val_inputs, val_labels = (\n",
        "                    val_data[\"image\"].to(device),\n",
        "                    val_data[\"label\"].to(device),\n",
        "                )\n",
        "                val_outputs = inference(val_inputs)\n",
        "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
        "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "                dice_metric_batch(y_pred=val_outputs, y=val_labels)\n",
        "\n",
        "            metric = dice_metric.aggregate().item()\n",
        "            metric_values.append(metric)\n",
        "            metric_batch = dice_metric_batch.aggregate()\n",
        "            metric_tc = metric_batch[0].item()\n",
        "            metric_values_tc.append(metric_tc)\n",
        "            metric_wt = metric_batch[1].item()\n",
        "            metric_values_wt.append(metric_wt)\n",
        "            metric_et = metric_batch[2].item()\n",
        "            metric_values_et.append(metric_et)\n",
        "            dice_metric.reset()\n",
        "            dice_metric_batch.reset()\n",
        "\n",
        "            if metric > best_metric:\n",
        "                best_metric = metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                best_metrics_epochs_and_time[0].append(best_metric)\n",
        "                best_metrics_epochs_and_time[1].append(best_metric_epoch)\n",
        "                best_metrics_epochs_and_time[2].append(time.time() - total_start)\n",
        "                torch.save(\n",
        "                    model.state_dict(),\n",
        "                    os.path.join(root_dir, \"best_metric_model.pth\"),\n",
        "                )\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
        "                f\" tc: {metric_tc:.4f} wt: {metric_wt:.4f} et: {metric_et:.4f}\"\n",
        "                f\"\\nbest mean dice: {best_metric:.4f}\"\n",
        "                f\" at epoch: {best_metric_epoch}\"\n",
        "            )\n",
        "    print(f\"time consuming of epoch {epoch + 1} is: {(time.time() - epoch_start):.4f}\")\n",
        "total_time = time.time() - total_start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "PdTnDwxdbsLC"
      },
      "outputs": [],
      "source": [
        "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}, total time: {total_time}.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "torch.save(model.state_dict(), os.path.join(save_path, \"best_metric_model.pth\"))\n",
        "print(\"✅ Model saved to Google Drive!\")\n",
        "\n",
        "# Save metrics\n",
        "import json\n",
        "\n",
        "metrics_dict = {\n",
        "    \"epoch_loss_values\": epoch_loss_values,\n",
        "    \"metric_values\": metric_values,\n",
        "    \"metric_values_tc\": metric_values_tc,\n",
        "    \"metric_values_wt\": metric_values_wt,\n",
        "    \"metric_values_et\": metric_values_et\n",
        "}\n",
        "\n",
        "with open(os.path.join(save_path, \"training_metrics.json\"), \"w\") as f:\n",
        "    json.dump(metrics_dict, f)\n",
        "\n",
        "print(\"📊 Metrics saved!\")\n",
        "\n",
        "# Save loss curve plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(epoch_loss_values)\n",
        "plt.title(\"Loss over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(save_path, \"loss_curve.png\"))\n",
        "print(\"📈 Loss curve saved!\")\n"
      ],
      "metadata": {
        "id": "IJV4kPZHbG2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqZdwGoBbsLC"
      },
      "source": [
        "## Plot the loss and metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jHC3-jSbsLC"
      },
      "outputs": [],
      "source": [
        "plt.figure(\"train\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Epoch Average Loss\")\n",
        "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
        "y = epoch_loss_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y, color=\"red\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Val Mean Dice\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
        "y = metric_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y, color=\"green\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(\"train\", (18, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Val Mean Dice TC\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values_tc))]\n",
        "y = metric_values_tc\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y, color=\"blue\")\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"Val Mean Dice WT\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values_wt))]\n",
        "y = metric_values_wt\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y, color=\"brown\")\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"Val Mean Dice ET\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values_et))]\n",
        "y = metric_values_et\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y, color=\"purple\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0qEHvgbbsLC"
      },
      "source": [
        "## Check best pytorch model output with the input image and label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90Ka-Lb3bsLC"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\"), weights_only=True))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # select one image to evaluate and visualize the model output\n",
        "    val_input = val_ds[6][\"image\"].unsqueeze(0).to(device)\n",
        "    roi_size = (128, 128, 64)\n",
        "    sw_batch_size = 4\n",
        "    val_output = inference(val_input)\n",
        "    val_output = post_trans(val_output[0])\n",
        "    plt.figure(\"image\", (24, 6))\n",
        "    for i in range(4):\n",
        "        plt.subplot(1, 4, i + 1)\n",
        "        plt.title(f\"image channel {i}\")\n",
        "        plt.imshow(val_ds[6][\"image\"][i, :, :, 70].detach().cpu(), cmap=\"gray\")\n",
        "    plt.show()\n",
        "    # visualize the 3 channels label corresponding to this image\n",
        "    plt.figure(\"label\", (18, 6))\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i + 1)\n",
        "        plt.title(f\"label channel {i}\")\n",
        "        plt.imshow(val_ds[6][\"label\"][i, :, :, 70].detach().cpu())\n",
        "    plt.show()\n",
        "    # visualize the 3 channels model output corresponding to this image\n",
        "    plt.figure(\"output\", (18, 6))\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i + 1)\n",
        "        plt.title(f\"output channel {i}\")\n",
        "        plt.imshow(val_output[i, :, :, 70].detach().cpu())\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HkaUV-SbsLC"
      },
      "source": [
        "## Evaluation on original image spacings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1Ye0vAhbsLC"
      },
      "outputs": [],
      "source": [
        "val_org_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\"]),\n",
        "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
        "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
        "        Spacingd(keys=[\"image\"], pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n",
        "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_org_ds = DecathlonDataset(\n",
        "    root_dir=root_dir,\n",
        "    task=\"Task01_BrainTumour\",\n",
        "    transform=val_org_transforms,\n",
        "    section=\"validation\",\n",
        "    download=False,\n",
        "    num_workers=4,\n",
        "    cache_num=0,\n",
        ")\n",
        "val_org_loader = DataLoader(val_org_ds, batch_size=1, shuffle=False, num_workers=4)\n",
        "\n",
        "post_transforms = Compose(\n",
        "    [\n",
        "        Invertd(\n",
        "            keys=\"pred\",\n",
        "            transform=val_org_transforms,\n",
        "            orig_keys=\"image\",\n",
        "            meta_keys=\"pred_meta_dict\",\n",
        "            orig_meta_keys=\"image_meta_dict\",\n",
        "            meta_key_postfix=\"meta_dict\",\n",
        "            nearest_interp=False,\n",
        "            to_tensor=True,\n",
        "            device=\"cpu\",\n",
        "        ),\n",
        "        Activationsd(keys=\"pred\", sigmoid=True),\n",
        "        AsDiscreted(keys=\"pred\", threshold=0.5),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBgOOLmibsLC"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\"), weights_only=True))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for val_data in val_org_loader:\n",
        "        val_inputs = val_data[\"image\"].to(device)\n",
        "        val_data[\"pred\"] = inference(val_inputs)\n",
        "        val_data = [post_transforms(i) for i in decollate_batch(val_data)]\n",
        "        val_outputs, val_labels = from_engine([\"pred\", \"label\"])(val_data)\n",
        "        dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "        dice_metric_batch(y_pred=val_outputs, y=val_labels)\n",
        "\n",
        "    metric_org = dice_metric.aggregate().item()\n",
        "    metric_batch_org = dice_metric_batch.aggregate()\n",
        "\n",
        "    dice_metric.reset()\n",
        "    dice_metric_batch.reset()\n",
        "\n",
        "metric_tc, metric_wt, metric_et = metric_batch_org[0].item(), metric_batch_org[1].item(), metric_batch_org[2].item()\n",
        "\n",
        "print(\"Metric on original image spacing: \", metric_org)\n",
        "print(f\"metric_tc: {metric_tc:.4f}\")\n",
        "print(f\"metric_wt: {metric_wt:.4f}\")\n",
        "print(f\"metric_et: {metric_et:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls best_metric_model.pth"
      ],
      "metadata": {
        "id": "T7W1e6WoXrTN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}